{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Raw BigEarthNet Data\n",
    "\n",
    "After understanding where the patches come from and how the patches were annotated, the following section will present and discuss the files inside the archives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BigEarthNet-S2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The general contents of the BigEarthNet-S2 archive looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove-input\n",
    "\n",
    "from bigearthnet_docs import get_s1_example_folder_path, get_s2_example_folder_path\n",
    "from rich import print\n",
    "from rich.tree import Tree\n",
    "from rich.markup import escape\n",
    "from rich.text import Text\n",
    "from pathlib import Path\n",
    "from pydantic import validate_arguments, DirectoryPath\n",
    "import natsort\n",
    "\n",
    "ben_s2_path = get_s2_example_folder_path()\n",
    "\n",
    "\n",
    "def _first_dir_natsort_key(path: Path) -> str:\n",
    "    \"\"\"Directories should come first\"\"\"\n",
    "    prefix = 0 if path.is_dir() else 1\n",
    "    return f\"{prefix}{path}\"\n",
    "\n",
    "\n",
    "def _walk_ben_directory(directory: Path, tree: Tree):\n",
    "    \"\"\"\n",
    "    Recursively build a BigEarthNet directory\n",
    "    \"\"\"\n",
    "    # Sort dirs first\n",
    "    paths = sorted(\n",
    "        Path(directory).iterdir(), key=natsort.natsort_keygen(_first_dir_natsort_key)\n",
    "    )\n",
    "    for path in paths:\n",
    "        if path.name.startswith(\".\"):\n",
    "            continue\n",
    "        if path.is_dir():\n",
    "            branch = tree.add(\n",
    "                # f\":open_file_folder: [link file://{path}]{escape(path.name)}\"\n",
    "                f\":open_file_folder: [bold]{escape(path.name)}\"\n",
    "            )\n",
    "            _walk_ben_directory(path, branch)\n",
    "        else:\n",
    "            text_filename = Text(path.name)\n",
    "            text_filename.highlight_regex(r\".*_\\d\\d?_\", \"dim\")\n",
    "            text_filename.highlight_words([\"labels_metadata.json\"], \"bold\")\n",
    "            text_filename.highlight_regex(r\"(?<=_).*.tif\", \"bold\")\n",
    "            # text_filename.stylize(f\"link file://{path}\")\n",
    "            icon = \"ðŸ—ºï¸ \" if path.suffix == \".tif\" else \"ðŸ“„ \"\n",
    "            tree.add(Text(icon) + text_filename)\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def walk_ben_directory(directory: DirectoryPath) -> Tree:\n",
    "    directory = directory.resolve()\n",
    "    tree = Tree(\n",
    "        # f\":open_file_folder: [link file://{directory}]{directory.name}\"\n",
    "        f\":open_file_folder: [bold]{directory.name}\"\n",
    "    )\n",
    "    _walk_ben_directory(directory, tree)\n",
    "    return tree\n",
    "\n",
    "\n",
    "walk_ben_directory(ben_s2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "With the following conventions:\n",
    "- Each folder coressponds to a single patch\n",
    "- The `patch_name` is encoded as the name of the folder\n",
    "- Each patch folder contains a [GeoTIFF](https://en.wikipedia.org/wiki/GeoTIFF) file for each of the 12 bands.\n",
    "  - The name of the GeoTIFF file is encoded as `<patch_name>_<band>.tif`.\n",
    "- The [JSON](https://en.wikipedia.org/wiki/JSON) file, named `<patch_name>_labels_metadata.json`, contains the metadata\n",
    "\n",
    "The prettified contents of a metadata file is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove-input\n",
    "\n",
    "from rich import print_json\n",
    "from copy import copy\n",
    "import json\n",
    "\n",
    "ben_s2_json_file_paths = list(Path(ben_s2_path).rglob(\"*.json\"))\n",
    "ben_s2_json_fp = ben_s2_json_file_paths[0]\n",
    "text = ben_s2_json_fp.read_text()\n",
    "j = json.loads(text)\n",
    "simple_j = copy(j)\n",
    "simple_j[\"projection\"] = simple_j[\"projection\"][:75] + \"...\"\n",
    "\n",
    "print_json(data=simple_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- `labels`: Lists the older {ref}`CLC Level-3 nomenclature <clc-level-3>` labels of the patch\n",
    "- `tile_source`: Shows the source tile that was further processed with [sen2cor](https://step.esa.int/main/snap-supported-plugins/sen2cor/) to generate the atmospherically corrected [L2A](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/product-formatting) product tile\n",
    "- `acquisition_date`: Encodes the acquisition date of the tile in the `YYYY-MM-DD hh:mm:ss` format\n",
    "- `coordinates`: Encodes the upper left x/y (`ulx`/`uly`) and lower right x/y (`lrx`/`lry`) coordinates of the patch\n",
    "- `projection`: Relates the values of the `coordinates` to the given coordinate reference systems (CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The unshorted (prettified) `projection` entry looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove-input\n",
    "import pyproj\n",
    "\n",
    "print(pyproj.CRS.from_user_input(j[\"projection\"]).to_wkt(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `projection` entry encodes the CRS information in the [WKT](https://en.wikipedia.org/wiki/Well-known_text_representation_of_coordinate_reference_systems) format.\n",
    "For most use-cases, it is sufficient to know, that the combination of the CRS and `coordinates` values define the exact location of a patch.\n",
    "For more details about what coordinate reference systems are feel free to take a look at one of the following introductory courses:\n",
    "- [earthdatascience earth-analytics course](https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/)\n",
    "- [gisbooklet](https://bookdown.org/tep/gisbooklet/introduction-to-coordinate-reference-system.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigEarthNet-S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove-input\n",
    "\n",
    "ben_s1_path = get_s1_example_folder_path()\n",
    "walk_ben_directory(ben_s1_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following conventions:\n",
    "- Each folder coressponds to a single patch\n",
    "- The `patch_name` is encoded as the name of the folder\n",
    "- Both bands `VH` and `VV` are saved as an indivdual [GeoTIFF](https://en.wikipedia.org/wiki/GeoTIFF) file\n",
    "  - The name of the GeoTIFF file is encoded as `<patch_name>_<band>.tif`.\n",
    "- The [JSON](https://en.wikipedia.org/wiki/JSON) file, named `<patch_name>_labels_metadata.json`, contains the metadata\n",
    "\n",
    "The prettified contents of a metadata file is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove-input\n",
    "\n",
    "from rich import print_json\n",
    "from copy import copy\n",
    "import json\n",
    "\n",
    "ben_s1_json_file_paths = list(Path(ben_s1_path).rglob(\"*.json\"))\n",
    "ben_s1_json_fp = ben_s1_json_file_paths[0]\n",
    "text = ben_s1_json_fp.read_text()\n",
    "j = json.loads(text)\n",
    "simple_j = copy(j)\n",
    "simple_j[\"projection\"] = simple_j[\"projection\"][:75] + \"...\"\n",
    "\n",
    "print_json(data=simple_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "Compared to the BigEarthNet-S2 metadata file, BigEarthNet-S1:\n",
    "- calls the date field `acquisition_time` and not `acquisition_date` (S2).\n",
    "- Encodes the date with `YYYY-MM-DD`T`hh:mm:ss` and not `YYYY-MM-DD hh:mm:ss` (S2)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metadata Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The advantages of having a JSON metadata file in every patch folder are:\n",
    "1. JSON is well known data format and has excellent library support\n",
    "2. Is human-readable (not a binary format)\n",
    "3. Locating the metadata _next_ to the images allows the end-user to easily select subsets of the archive without having to deal with the metadata separately\n",
    "   - Copying the patches of interest will always include the metadata\n",
    "\n",
    "The main disadvantages is that each archive (~80GB) has to be downloaded and that it is not easy to perform statistical analysis.\n",
    "The metadata files have to be parsed and converted into a common data structure first.\n",
    "Usually, the metadata is converted into a tabular format to allow the use of data analysis tools, such as [pandas](https://pandas.pydata.org/), or the geographical extension, [geopandas](https://geopandas.org/en/stable/).\n",
    "\n",
    "### Pre-converted metadata\n",
    "Instead of re-writing another parsing script, we recommend to use [](ben_gdf_builder:intro).\n",
    "This library parses the all JSON files from the archive and converts them to a common geopandas parquet file.\n",
    "See [](ben_gdf_builder:intro) for more information.\n",
    "\n",
    "Do make it simpler to do statistical analysis, we provide pre-converted files.\n",
    "These files (and the links) may change in the future!\n",
    "\n",
    "- BigEarthNet-S2\n",
    "   - [raw_ben_gdf.parquet](https://tubcloud.tu-berlin.de/s/gxp8KGk8TfcH6rR)\n",
    "      - The original parquet file that is produced by parsing all metadata files and projecting to a common CRS\n",
    "   - [extended_ben_gdf.parquet](https://tubcloud.tu-berlin.de/s/5cstd7EJRB8kCyL)\n",
    "      - An extended version of the `raw_ben_gdf.parquet` file with additional metadata:\n",
    "        - 19-class nomenclature\n",
    "        - Covered by seasonal snow\n",
    "        - Covered by clouds or shadows\n",
    "        - Original split\n",
    "        - Country\n",
    "        - Season\n",
    "   - [final_ben.parquet](https://tubcloud.tu-berlin.de/s/wtqZQKawLaBZZY8)\n",
    "     - The recommended subset of `extended_ben_gdf.parquet`, where no patch is covered by snow, clouds or shadows and every patch has at least one target label in the 19-class nomenclature\n",
    "\n",
    "#### Example output\n",
    "\n",
    "<!-- :::{dropdown} BigEarthNet-S2-Example Metadata in tabular form\n",
    ":::{glue:} ben-s2-gdf\n",
    "::: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigearthnet_gdf_builder.builder import get_gdf_from_s2_patch_dir\n",
    "\n",
    "# gdf_builder also has a CLI tool to convert the entire archive into a single\n",
    "# parquet file!\n",
    "# Example \"raw\" subset\n",
    "gdf = get_gdf_from_s2_patch_dir(ben_s2_path)\n",
    "# showing first row as tables have display issues\n",
    "gdf.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parquet files allow for easy data-processing and visualization.\n",
    "These files work particularly well with geopandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove-input\n",
    "gdf[[False, True, False]].explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigearthnet_gdf_builder.builder import add_full_ben_s2_metadata\n",
    "\n",
    "# also provides a quick way to add important metadata\n",
    "# example \"metadata\" subset\n",
    "meta_gdf = add_full_ben_s2_metadata(gdf)\n",
    "# showing first row as tables have display issues\n",
    "meta_gdf.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    ":::{important}\n",
    "Instead of writing another metadata loading script:\n",
    "- Download one of the pre-converted files or\n",
    "- Use the [](ben_gdf_builder:intro) tool to convert the metadata into a tabular format\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64eb03049fb0f2dfb160c500803d509ea554795c7f2b025157942206e9010cc7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('bigearthnet-docs-ESkrV8a6-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
